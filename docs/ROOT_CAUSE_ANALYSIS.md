# üîç PH√ÇN T√çCH CH·ª®C NƒÇNG ROOT CAUSE ANALYSIS (RCA)

## üìã T·ªîNG QUAN

**Root Cause Analysis (RCA)** l√† m·ªôt ch·ª©c nƒÉng AI-powered quan tr·ªçng trong h·ªá th·ªëng QUALIFY.AI, t·ª± ƒë·ªông ph√¢n t√≠ch c√°c test failures ƒë·ªÉ x√°c ƒë·ªãnh nguy√™n nh√¢n g·ªëc r·ªÖ v√† ƒë∆∞a ra c√°c khuy·∫øn ngh·ªã kh·∫Øc ph·ª•c.

---

## üèóÔ∏è KI·∫æN TR√öC V√Ä C√ÅC TH√ÄNH PH·∫¶N

### 1. **Backend Components**

#### 1.1. RootCauseAnalyzer Class (`backend/services/ai-analysis-service/app/analyzers/rca.py`)

**Ch·ª©c nƒÉng ch√≠nh:**
- Ph√¢n t√≠ch test failures s·ª≠ d·ª•ng OpenAI API
- So s√°nh v·ªõi historical failures ƒë·ªÉ t√¨m patterns
- T·∫°o executive summaries cho management

**C√°c ph∆∞∆°ng th·ª©c:**

```python
async def analyze_failure(
    test_name: str,
    error_message: str,
    stack_trace: str,
    test_description: str = "",
    historical_failures: Optional[List[Dict[str, Any]]] = None
) -> Dict[str, Any]
```

**Input:**
- `test_name`: T√™n test case
- `error_message`: Th√¥ng b√°o l·ªói t·ª´ test failure
- `stack_trace`: Full stack trace
- `test_description`: M√¥ t·∫£ test (optional)
- `historical_failures`: Danh s√°ch c√°c failures tr∆∞·ªõc ƒë√≥ c·ªßa c√πng test

**Output:**
```json
{
    "root_cause": "detailed explanation",
    "confidence": 85,
    "category": "Code Bug",
    "similar_patterns": ["pattern1", "pattern2"],
    "recommended_actions": ["action1", "action2", "action3"],
    "technical_details": "deeper technical analysis",
    "analysis_model": "gpt-4",
    "tokens_used": 1234
}
```

#### 1.2. API Endpoint (`backend/services/ai-analysis-service/app/main.py`)

**Endpoint:** `POST /api/ai/analyze/rca`

**Request:**
```json
{
    "test_result_id": "uuid"
}
```

**Lu·ªìng x·ª≠ l√Ω:**
1. L·∫•y test result t·ª´ database
2. Query historical failures (5 failures g·∫ßn nh·∫•t c·ªßa c√πng test)
3. G·ªçi `RootCauseAnalyzer.analyze_failure()`
4. L∆∞u k·∫øt qu·∫£ v√†o `ai_analyses` table
5. Return analysis result

#### 1.3. Database Schema (`backend/shared/models.py`)

**Table: `ai_analyses`**
```python
class AIAnalysis(Base):
    id: UUID
    test_result_id: UUID (FK -> test_results)
    analysis_type: Enum (ROOT_CAUSE, FLAKY_DETECTION, etc.)
    result: JSONB  # Full analysis result
    confidence: Float (0.0 - 1.0)
    prompt_used: Text
    model_used: String
    similar_issues: JSONB
    created_at: DateTime
```

---

## üîÑ LU·ªíNG X·ª¨ L√ù CHI TI·∫æT

### **Step 1: Trigger Analysis**
```
User clicks "Analyze Root Cause" on failed test
    ‚Üì
Frontend calls: POST /api/ai/analyze/rca
    ‚Üì
Backend receives request with test_result_id
```

### **Step 2: Data Collection**
```
Backend queries database:
    ‚Üì
1. Get test_result by ID
   - test_name
   - error_message
   - error_trace (stack trace)
   - description
   - history_id
    ‚Üì
2. Get historical failures
   - Query test_results WHERE history_id = same
   - Filter: status IN ('failed', 'broken')
   - Order by: created_at DESC
   - Limit: 5 failures
    ‚Üì
3. Prepare historical context
   - Format: Date, Error message (truncated)
```

### **Step 3: AI Analysis**
```
RootCauseAnalyzer.analyze_failure():
    ‚Üì
1. Prepare prompt template v·ªõi:
   - Test information
   - Failure details (error + stack trace)
   - Historical context
    ‚Üì
2. Call OpenAI API:
   - Model: gpt-4 (configurable)
   - Temperature: 0.7 (configurable)
   - Response format: JSON
   - System prompt: "Expert QA engineer"
    ‚Üì
3. Parse JSON response:
   - root_cause
   - confidence
   - category
   - similar_patterns
   - recommended_actions
   - technical_details
```

### **Step 4: Store Results**
```
Create AIAnalysis record:
    ‚Üì
- test_result_id
- analysis_type: ROOT_CAUSE
- result: Full JSON analysis
- confidence: 0.0 - 1.0
- model_used: "gpt-4"
- prompt_used: "RCA analysis prompt"
    ‚Üì
Save to database
    ‚Üì
Return to frontend
```

---

## üìä C√ÅC LO·∫†I PH√ÇN T√çCH

### **1. Root Cause Identification**
AI ph√¢n t√≠ch ƒë·ªÉ x√°c ƒë·ªãnh nguy√™n nh√¢n g·ªëc r·ªÖ:
- **Code Bug**: L·ªói logic trong code
- **Infrastructure**: V·∫•n ƒë·ªÅ v·ªÅ m√¥i tr∆∞·ªùng, network, database
- **Test Flakiness**: Test kh√¥ng ·ªïn ƒë·ªãnh
- **Configuration**: C·∫•u h√¨nh sai
- **Data Issue**: D·ªØ li·ªáu test kh√¥ng ƒë√∫ng

### **2. Confidence Level**
- **0-100%**: M·ª©c ƒë·ªô tin c·∫≠y c·ªßa ph√¢n t√≠ch
- D·ª±a tr√™n:
  - ƒê·ªô r√µ r√†ng c·ªßa error message
  - Stack trace c√≥ ƒë·∫ßy ƒë·ªß kh√¥ng
  - Historical patterns c√≥ match kh√¥ng

### **3. Similar Patterns**
So s√°nh v·ªõi historical failures ƒë·ªÉ t√¨m:
- C√πng error message
- C√πng stack trace pattern
- C√πng test case ƒë√£ fail tr∆∞·ªõc ƒë√≥
- Similarity score > 70%

### **4. Recommended Actions**
AI ƒë∆∞a ra c√°c b∆∞·ªõc c·ª• th·ªÉ ƒë·ªÉ fix:
- V√≠ d·ª•: "Check database connection", "Verify API endpoint", etc.

---

## üéØ PROMPT ENGINEERING

### **System Prompt:**
```
"You are an expert QA engineer specializing in root cause analysis."
```

### **User Prompt Template:**
```
Test Information:
- Test Name: {test_name}
- Description: {test_description}

Failure Details:
- Error Message: {error_message}
- Stack Trace: 
{stack_trace}

Historical Context:
{historical_context}

Please analyze this test failure and provide:
1. Root Cause: The most likely underlying issue causing the failure
2. Confidence Level: Your confidence in this analysis (0-100%)
3. Similar Issues: Any patterns matching known issues
4. Recommended Actions: Specific steps to resolve the issue
5. Category: Classify as (Infrastructure/Code Bug/Test Flakiness/Configuration/Data Issue)

Provide your analysis in JSON format:
{
    "root_cause": "detailed explanation",
    "confidence": 85,
    "category": "category name",
    "similar_patterns": ["pattern1", "pattern2"],
    "recommended_actions": ["action1", "action2", "action3"],
    "technical_details": "deeper technical analysis"
}
```

---

## ‚úÖ ƒêI·ªÇM M·∫†NH

1. **T·ª± ƒë·ªông h√≥a**: Kh√¥ng c·∫ßn manual analysis
2. **Historical Context**: S·ª≠ d·ª•ng d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c
3. **Structured Output**: JSON format d·ªÖ parse v√† hi·ªÉn th·ªã
4. **Confidence Score**: Gi√∫p ƒë√°nh gi√° ƒë·ªô tin c·∫≠y
5. **Category Classification**: Ph√¢n lo·∫°i gi√∫p prioritize fixes
6. **Similar Pattern Detection**: T√¨m c√°c failures t∆∞∆°ng t·ª±
7. **Actionable Recommendations**: ƒê∆∞a ra c√°c b∆∞·ªõc c·ª• th·ªÉ ƒë·ªÉ fix

---

## ‚ö†Ô∏è ƒêI·ªÇM Y·∫æU V√Ä H·∫†N CH·∫æ

### **1. Ph·ª• thu·ªôc v√†o OpenAI API**
- C·∫ßn API key v√† c√≥ chi ph√≠
- C√≥ th·ªÉ b·ªã rate limit
- C·∫ßn internet connection

### **2. Ch·∫•t l∆∞·ª£ng ph·ª• thu·ªôc v√†o d·ªØ li·ªáu ƒë·∫ßu v√†o**
- Error message kh√¥ng r√µ r√†ng ‚Üí ph√¢n t√≠ch k√©m
- Stack trace thi·∫øu ‚Üí confidence th·∫•p
- Kh√¥ng c√≥ historical data ‚Üí m·∫•t context

### **3. Similarity Detection ƒë∆°n gi·∫£n**
```python
def _calculate_similarity(...) -> float:
    # Simple word overlap similarity
    # Ch∆∞a d√πng embeddings ho·∫∑c advanced NLP
```
- Ch·ªâ d√πng word overlap, ch∆∞a d√πng semantic similarity
- C√≥ th·ªÉ miss c√°c patterns t∆∞∆°ng t·ª± nh∆∞ng kh√°c c√°ch di·ªÖn ƒë·∫°t

### **4. Ch∆∞a t√≠ch h·ª£p v·ªõi Frontend**
- Backend ƒë√£ c√≥ nh∆∞ng frontend ch∆∞a c√≥ UI
- Ch∆∞a c√≥ button "Analyze Root Cause" trong TestDetailsDialog
- Ch∆∞a hi·ªÉn th·ªã RCA results

### **5. Batch Analysis ch∆∞a t·ªëi ∆∞u**
- `analyze_batch()` g·ªçi tu·∫ßn t·ª± t·ª´ng test
- Ch∆∞a parallel processing
- C√≥ th·ªÉ ch·∫≠m v·ªõi nhi·ªÅu tests

### **6. Ch∆∞a c√≥ Caching**
- M·ªói l·∫ßn analyze l·∫°i g·ªçi API
- Kh√¥ng cache k·∫øt qu·∫£ cho c√πng test failure
- T·ªën chi ph√≠ v√† th·ªùi gian

---

## üöÄ ƒê·ªÄ XU·∫§T C·∫¢I THI·ªÜN

### **1. Frontend Integration**

#### **A. Th√™m RCA Button v√†o TestDetailsDialog**
```typescript
// Trong TestDetailsDialog.tsx
{isFailed && (
  <Button
    onClick={handleAnalyzeRCA}
    disabled={analyzing}
    className="bg-qualify-teal"
  >
    {analyzing ? 'Analyzing...' : 'Analyze Root Cause'}
  </Button>
)}
```

#### **B. Hi·ªÉn th·ªã RCA Results**
```typescript
// Component m·ªõi: RCAResults.tsx
interface RCAResultsProps {
  analysis: {
    root_cause: string;
    confidence: number;
    category: string;
    similar_patterns: string[];
    recommended_actions: string[];
    technical_details: string;
  };
}
```

#### **C. RCA Panel trong Dashboard**
- Hi·ªÉn th·ªã top failed tests ƒë√£ ƒë∆∞·ª£c analyze
- Show confidence scores
- Quick actions ƒë·ªÉ fix

### **2. C·∫£i thi·ªán Similarity Detection**

#### **A. S·ª≠ d·ª•ng Embeddings**
```python
from openai import Embeddings

def _calculate_similarity_with_embeddings(error1, trace1, error2, trace2):
    # Generate embeddings
    emb1 = get_embedding(error1 + trace1)
    emb2 = get_embedding(error2 + trace2)
    
    # Cosine similarity
    return cosine_similarity(emb1, emb2)
```

#### **B. Pattern Extraction**
- Extract common patterns t·ª´ stack traces
- Classify error types (NullPointerException, TimeoutError, etc.)
- Match patterns thay v√¨ ch·ªâ text similarity

### **3. Caching Strategy**

#### **A. Cache Analysis Results**
```python
# Redis cache
cache_key = f"rca:{test_result_id}:{error_hash}"
cached_result = await redis.get(cache_key)

if cached_result:
    return json.loads(cached_result)

# Analyze and cache
result = await analyze_failure(...)
await redis.setex(cache_key, 3600, json.dumps(result))  # 1 hour TTL
```

#### **B. Smart Caching**
- Cache d·ª±a tr√™n error message hash
- N·∫øu c√πng error ‚Üí reuse analysis
- Invalidate khi test code thay ƒë·ªïi

### **4. Batch Processing Optimization**

#### **A. Parallel Processing**
```python
import asyncio

async def analyze_batch_parallel(failures: List[Dict]):
    tasks = [
        analyze_failure(**failure) 
        for failure in failures
    ]
    return await asyncio.gather(*tasks)
```

#### **B. Rate Limiting**
- Implement rate limiting cho OpenAI API
- Queue system cho batch requests
- Retry logic v·ªõi exponential backoff

### **5. Enhanced Prompt Engineering**

#### **A. Few-shot Learning**
```python
prompt_template = """
Here are examples of good RCA analyses:

Example 1:
Test: test_user_login
Error: ConnectionTimeout
Root Cause: Database connection pool exhausted
Category: Infrastructure
Confidence: 90%

Example 2:
...

Now analyze this failure:
{test_info}
"""
```

#### **B. Domain-specific Prompts**
- Different prompts cho different test types (API, UI, Integration)
- Include domain knowledge (e.g., common API errors)

### **6. Integration v·ªõi External Systems**

#### **A. JIRA Integration**
```python
# Auto-create JIRA ticket v·ªõi RCA results
jira_ticket = {
    "summary": f"Test Failure: {test_name}",
    "description": analysis["root_cause"],
    "labels": [analysis["category"]],
    "priority": calculate_priority(analysis["confidence"])
}
```

#### **B. Slack/Teams Notifications**
- Auto-notify team khi c√≥ high-confidence RCA
- Include recommended actions

### **7. Analytics & Reporting**

#### **A. RCA Accuracy Tracking**
```python
# Track khi developer confirms RCA
class RCAAccuracy:
    analysis_id: UUID
    confirmed_by: UUID (user_id)
    was_correct: bool
    actual_root_cause: str (if different)
```

#### **B. RCA Dashboard**
- Success rate c·ªßa RCA analyses
- Most common root causes
- Average time to fix based on RCA

---

## üìà METRICS & MONITORING

### **Key Metrics:**
1. **Analysis Success Rate**: % analyses completed successfully
2. **Average Confidence**: Mean confidence score
3. **Category Distribution**: Breakdown by category
4. **API Cost**: Tokens used per analysis
5. **Response Time**: Time to complete analysis
6. **Cache Hit Rate**: % requests served from cache

### **Monitoring:**
- Track OpenAI API errors
- Monitor rate limits
- Alert khi confidence th·∫•p (< 50%)
- Track analysis accuracy (n·∫øu c√≥ feedback)

---

## üîß CONFIGURATION

### **Environment Variables:**
```bash
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.7
RCA_CACHE_TTL=3600
RCA_MAX_HISTORICAL_FAILURES=5
RCA_SIMILARITY_THRESHOLD=0.7
```

### **Tunable Parameters:**
- `temperature`: 0.0-1.0 (lower = more deterministic)
- `max_historical_failures`: S·ªë failures ƒë·ªÉ analyze (default: 5)
- `similarity_threshold`: Threshold ƒë·ªÉ match similar failures (default: 0.7)
- `cache_ttl`: Th·ªùi gian cache (seconds)

---

## üìù V√ç D·ª§ S·ª¨ D·ª§NG

### **Example 1: Simple Failure**
```json
Input:
{
    "test_name": "test_user_login",
    "error_message": "ConnectionTimeout: Unable to connect to database",
    "stack_trace": "at Database.connect()...",
    "historical_failures": []
}

Output:
{
    "root_cause": "Database connection timeout indicates infrastructure issue. Possible causes: database server down, network issues, or connection pool exhausted.",
    "confidence": 85,
    "category": "Infrastructure",
    "similar_patterns": [],
    "recommended_actions": [
        "Check database server status",
        "Verify network connectivity",
        "Review connection pool configuration",
        "Check database logs for errors"
    ],
    "technical_details": "ConnectionTimeout typically occurs when the database server is unreachable or overloaded..."
}
```

### **Example 2: With Historical Context**
```json
Input:
{
    "test_name": "test_checkout_process",
    "error_message": "AssertionError: Expected total $100 but got $105",
    "stack_trace": "...",
    "historical_failures": [
        {
            "date": "2024-01-15",
            "error_message": "AssertionError: Expected total $50 but got $55"
        }
    ]
}

Output:
{
    "root_cause": "Price calculation error appears to be recurring. This test has failed with similar price discrepancies before (Jan 15). Likely a bug in the pricing calculation logic or tax computation.",
    "confidence": 92,
    "category": "Code Bug",
    "similar_patterns": [
        "Previous failure on 2024-01-15 with similar price mismatch"
    ],
    "recommended_actions": [
        "Review pricing calculation code",
        "Check tax computation logic",
        "Verify test data consistency",
        "Compare with previous failure to identify pattern"
    ]
}
```

---

## üéì K·∫æT LU·∫¨N

Root Cause Analysis l√† m·ªôt ch·ª©c nƒÉng m·∫°nh m·∫Ω nh∆∞ng c·∫ßn:

1. **‚úÖ Ho√†n thi·ªán Frontend Integration**: Th√™m UI ƒë·ªÉ trigger v√† hi·ªÉn th·ªã RCA
2. **‚úÖ C·∫£i thi·ªán Similarity Detection**: D√πng embeddings thay v√¨ word overlap
3. **‚úÖ Implement Caching**: Gi·∫£m chi ph√≠ v√† tƒÉng t·ªëc ƒë·ªô
4. **‚úÖ Batch Optimization**: Parallel processing cho nhi·ªÅu tests
5. **‚úÖ Enhanced Monitoring**: Track accuracy v√† success rate

V·ªõi nh·ªØng c·∫£i thi·ªán n√†y, RCA s·∫Ω tr·ªü th√†nh m·ªôt c√¥ng c·ª• c·ª±c k·ª≥ h·ªØu √≠ch cho QA teams ƒë·ªÉ nhanh ch√≥ng identify v√† fix test failures.

