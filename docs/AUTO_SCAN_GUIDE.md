# HÆ°á»›ng dáº«n Auto-Scan Allure Reports

## ğŸ¯ Tá»•ng quan

Report Watcher Service tá»± Ä‘á»™ng quÃ©t folder chá»©a Allure reports vÃ  import data vÃ o database má»—i 5 phÃºt.

## ğŸ“ Cáº¥u trÃºc Folder

```
D:\allure-reports\              # Base folder
â”œâ”€â”€ 13-11-2025\                 # Date folder (dd-mm-yyyy)
â”‚   â”œâ”€â”€ result-001.json         # Allure result files
â”‚   â”œâ”€â”€ result-002.json
â”‚   â””â”€â”€ result-003.json
â”œâ”€â”€ 14-11-2025\
â”‚   â”œâ”€â”€ result-001.json
â”‚   â””â”€â”€ result-002.json
â””â”€â”€ 15-11-2025\
    â””â”€â”€ result-001.json
```

**Quy táº¯c:**
- Folder tÃªn theo format: `dd-mm-yyyy` (VD: `13-11-2025`, `01-12-2025`)
- File JSON Ä‘áº·t trá»±c tiáº¿p trong folder ngÃ y
- File JSON cÃ³ format Allure standard

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### BÆ°á»›c 1: Táº¡o folder structure

#### Option A: Tá»± Ä‘á»™ng (dÃ¹ng script)

```bash
# Táº¡o sample reports
scripts\create-sample-reports.bat
```

Script sáº½ táº¡o:
- Folder `D:\allure-reports\`
- Subfolder vá»›i tÃªn ngÃ y hÃ´m nay
- Sample JSON file

#### Option B: Thá»§ cÃ´ng

```bash
# Táº¡o folder
mkdir D:\allure-reports
mkdir D:\allure-reports\13-11-2025

# Copy Allure JSON files vÃ o
copy path\to\allure-results\*.json D:\allure-reports\13-11-2025\
```

### BÆ°á»›c 2: Cáº¥u hÃ¬nh

Táº¡o file `.env` trong `backend/services/report-watcher/`:

```env
# Path to reports folder
ALLURE_REPORTS_PATH=D:/allure-reports

# Scan interval (minutes)
SCAN_INTERVAL_MINUTES=5

# Database
DATABASE_URL=postgresql+asyncpg://qualify:qualify_password@localhost:5432/qualify_db
REDIS_URL=redis://localhost:6379/0
```

### BÆ°á»›c 3: Start Service

#### Option A: Standalone (Development)

```bash
# Windows
scripts\start-watcher.bat

# Linux/Mac
cd backend/services/report-watcher
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8005
```

#### Option B: Docker (Production)

Update `docker-compose.yml`:

```yaml
services:
  report-watcher:
    build:
      context: ../../
      dockerfile: backend/services/report-watcher/Dockerfile
    container_name: qualify-watcher
    environment:
      ALLURE_REPORTS_PATH: /reports
      SCAN_INTERVAL_MINUTES: 5
      DATABASE_URL: postgresql+asyncpg://qualify:qualify_password@postgres:5432/qualify_db
    volumes:
      - D:/allure-reports:/reports
    ports:
      - "8005:8005"
    depends_on:
      - postgres
    restart: unless-stopped
```

```bash
docker-compose up -d report-watcher
```

### BÆ°á»›c 4: Verify

Kiá»ƒm tra service Ä‘ang cháº¡y:

```bash
# Health check
curl http://localhost:8005/health

# Xem status
curl http://localhost:8005/scan/status

# Xem files Ä‘Ã£ process
curl http://localhost:8005/scan/processed
```

## ğŸ”„ Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Service starts                              â”‚
â”‚     - Initial scan immediately                  â”‚
â”‚     - Schedule recurring scans (every 5 min)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Scan folder structure                       â”‚
â”‚     - Look for folders: dd-mm-yyyy              â”‚
â”‚     - Find *.json files in each folder          â”‚
â”‚     - Skip already processed files              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Load & Parse JSON                           â”‚
â”‚     - Read Allure JSON format                   â”‚
â”‚     - Extract test results                      â”‚
â”‚     - Calculate statistics                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Save to Database                            â”‚
â”‚     - Create/Get Project                        â”‚
â”‚     - Create/Get Test Suite                     â”‚
â”‚     - Create Test Run                           â”‚
â”‚     - Save Test Results                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Frontend Auto-Refresh                       â”‚
â”‚     - Dashboard loads data from DB              â”‚
â”‚     - Shows latest test results                 â”‚
â”‚     - Updates automatically                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Dashboard Integration

### Frontend tá»± Ä‘á»™ng load data

Update `frontend/app/dashboard/page.tsx`:

```typescript
useEffect(() => {
  // Fetch from API instead of mock data
  async function loadRealData() {
    const response = await fetch('http://localhost:8000/api/analytics/dashboard');
    const data = await response.json();
    setDashboardData(data);
  }
  
  loadRealData();
  
  // Auto-refresh every 5 minutes
  const interval = setInterval(loadRealData, 5 * 60 * 1000);
  return () => clearInterval(interval);
}, []);
```

## ğŸ® API Endpoints

### GET /scan/status
Xem tráº¡ng thÃ¡i scanner

```bash
curl http://localhost:8005/scan/status
```

Response:
```json
{
  "status": "running",
  "watch_folder": "D:/allure-reports",
  "scan_interval_minutes": 5,
  "processed_files_count": 42,
  "next_scan": "2025-11-13T12:35:00"
}
```

### POST /scan/trigger
Trigger scan thá»§ cÃ´ng

```bash
curl -X POST http://localhost:8005/scan/trigger
```

### GET /scan/processed
Xem files Ä‘Ã£ xá»­ lÃ½

```bash
curl http://localhost:8005/scan/processed
```

### DELETE /scan/reset
Reset danh sÃ¡ch files Ä‘Ã£ xá»­ lÃ½ (Ä‘á»ƒ scan láº¡i)

```bash
curl -X DELETE http://localhost:8005/scan/reset
```

## ğŸ“ VÃ­ dá»¥ thá»±c táº¿

### Scenario 1: CI/CD Integration

```yaml
# .gitlab-ci.yml
test:
  script:
    - pytest --alluredir=allure-results
    - |
      # Create date folder
      DATE=$(date +%d-%m-%Y)
      mkdir -p /mnt/reports/$DATE
      
      # Copy results
      cp allure-results/*.json /mnt/reports/$DATE/
      
      # Report Watcher will auto-scan within 5 minutes
```

### Scenario 2: Nightly Test Runs

```bash
# cron job (cháº¡y lÃºc 2 AM)
0 2 * * * /opt/run-tests.sh

# run-tests.sh
#!/bin/bash
DATE=$(date +%d-%m-%Y)
REPORT_DIR=/allure-reports/$DATE

mkdir -p $REPORT_DIR
cd /tests
pytest --alluredir=$REPORT_DIR
```

### Scenario 3: Multiple Projects

```
D:\allure-reports\
â”œâ”€â”€ project-a\
â”‚   â”œâ”€â”€ 13-11-2025\
â”‚   â”‚   â””â”€â”€ *.json
â”‚   â””â”€â”€ 14-11-2025\
â”‚       â””â”€â”€ *.json
â””â”€â”€ project-b\
    â””â”€â”€ 13-11-2025\
        â””â”€â”€ *.json
```

Update config Ä‘á»ƒ scan multiple folders hoáº·c cháº¡y multiple instances.

## ğŸ”§ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `ALLURE_REPORTS_PATH` | `D:/allure-reports` | Base folder chá»©a reports |
| `SCAN_INTERVAL_MINUTES` | `5` | Thá»i gian giá»¯a cÃ¡c láº§n scan |
| `DATABASE_URL` | - | PostgreSQL connection string |
| `REDIS_URL` | - | Redis connection string |

### Thay Ä‘á»•i scan interval

Trong file `.env`:
```env
SCAN_INTERVAL_MINUTES=10  # Scan má»—i 10 phÃºt
```

Hoáº·c trong code:
```python
scheduler.add_job(
    scan_and_process,
    'interval',
    minutes=10,  # Change here
    ...
)
```

## ğŸ› Troubleshooting

### Service khÃ´ng scan

**Kiá»ƒm tra:**
```bash
# Xem logs
curl http://localhost:8005/scan/status

# Check folder exists
ls D:\allure-reports

# Check permissions
```

### Files khÃ´ng Ä‘Æ°á»£c process

**NguyÃªn nhÃ¢n:**
- Folder name khÃ´ng Ä‘Ãºng format `dd-mm-yyyy`
- JSON khÃ´ng há»£p lá»‡
- File Ä‘Ã£ Ä‘Æ°á»£c process rá»“i

**Giáº£i phÃ¡p:**
```bash
# Reset processed files
curl -X DELETE http://localhost:8005/scan/reset

# Trigger manual scan
curl -X POST http://localhost:8005/scan/trigger
```

### Dashboard khÃ´ng hiá»ƒn thá»‹ data

**Kiá»ƒm tra:**
1. Backend services Ä‘ang cháº¡y
2. Database cÃ³ data
3. Frontend Ä‘ang gá»i Ä‘Ãºng API

```bash
# Check database
psql -U qualify -d qualify_db -c "SELECT COUNT(*) FROM test_results;"

# Check API
curl http://localhost:8000/api/analytics/dashboard
```

## ğŸ“ˆ Performance

### Optimization Tips

1. **Large folders:** Service xá»­ lÃ½ async, cÃ³ thá»ƒ handle hÃ ng trÄƒm files
2. **Database:** Index trÃªn `created_at`, `history_id` Ä‘á»ƒ query nhanh
3. **Memory:** Service track processed files in memory, restart Ä‘á»ƒ clear

### Monitoring

```bash
# Watch logs
tail -f logs/report-watcher.log

# Check metrics
curl http://localhost:8005/metrics
```

## ğŸ¯ Best Practices

1. âœ… **Naming Convention:** DÃ¹ng format `dd-mm-yyyy` Ä‘Ãºng chuáº©n
2. âœ… **File Organization:** Má»™t folder cho má»™t ngÃ y
3. âœ… **Cleanup:** XÃ³a folders cÅ© sau 30-90 ngÃ y
4. âœ… **Backup:** Backup database thÆ°á»ng xuyÃªn
5. âœ… **Monitoring:** Setup alerts náº¿u scan fails

## ğŸš€ Next Steps

1. Start Report Watcher Service
2. Add Allure JSON files vÃ o folder
3. Wait 5 minutes (hoáº·c trigger manual scan)
4. Refresh Dashboard Ä‘á»ƒ xem data

---

**Happy Auto-Scanning! ğŸ‰**

